//! æ‰¹å¤„ç†è®­ç»ƒç¤ºä¾‹
//!
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ‰¹å¤„ç†è®­ç»ƒæé«˜æ€§èƒ½

use mini_transformer::{
    TrainableTransformer, TextClassificationDataset, TensorExt,
};
use ndarray::Array2;
use std::time::Instant;

fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   æ‰¹å¤„ç†è®­ç»ƒ vs å•æ ·æœ¬è®­ç»ƒå¯¹æ¯”               â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // åˆ›å»ºæ•°æ®é›†
    println!("ğŸ“Š åŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®é›†...");
    let dataset = mini_transformer::create_sentiment_dataset();

    println!("  è¯æ±‡è¡¨å¤§å°: {}", dataset.vocab.vocab_size());
    println!("  è®­ç»ƒæ ·æœ¬: {}", dataset.train_len());
    println!("  æµ‹è¯•æ ·æœ¬: {}", dataset.test_len());
    println!("  ç±»åˆ«æ•°: {} (0=æ¶ˆæ, 1=ç§¯æ)\n", dataset.n_classes);

    // å‡†å¤‡æ•°æ®
    let max_seq_len = 10;
    let (train_inputs, train_targets) = dataset.encode_train(max_seq_len);
    let (test_inputs, test_targets) = dataset.encode_test(max_seq_len);

    // ============ å®éªŒ 1: å•æ ·æœ¬è®­ç»ƒ ============
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("å®éªŒ 1: å•æ ·æœ¬è®­ç»ƒ");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    let mut model_single = TrainableTransformer::new(
        dataset.vocab.vocab_size(),
        128,
        4,
        2,
        256,
        max_seq_len,
        dataset.n_classes,
    );

    let train_inputs_vec: Vec<Vec<usize>> = train_inputs
        .rows()
        .into_iter()
        .map(|row| row.to_vec())
        .collect();

    let test_inputs_vec: Vec<Vec<usize>> = test_inputs
        .rows()
        .into_iter()
        .map(|row| row.to_vec())
        .collect();

    let start_single = Instant::now();
    let (epoch_single, best_acc_single) = model_single.train(
        &train_inputs_vec,
        &train_targets,
        &test_inputs_vec,
        &test_targets,
        30,
        0.01,
        5,
    );
    let time_single = start_single.elapsed();

    let (final_test_loss_single, final_test_acc_single) =
        model_single.evaluate(&test_inputs_vec, &test_targets);

    println!("\nå•æ ·æœ¬è®­ç»ƒç»“æœ:");
    println!("  è®­ç»ƒæ—¶é—´: {:.2}s", time_single.as_secs_f32());
    println!("  æœ€ä½³ epoch: {}", epoch_single);
    println!("  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {:.2}%", best_acc_single * 100.0);
    println!("  æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_single * 100.0);

    // ============ å®éªŒ 2: æ‰¹å¤„ç†è®­ç»ƒ ============
    println!("\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("å®éªŒ 2: æ‰¹å¤„ç†è®­ç»ƒ (batch_size=8)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    let mut model_batch = TrainableTransformer::new(
        dataset.vocab.vocab_size(),
        128,
        4,
        2,
        256,
        max_seq_len,
        dataset.n_classes,
    );

    let test_inputs_vec2: Vec<Vec<usize>> = test_inputs
        .rows()
        .into_iter()
        .map(|row| row.to_vec())
        .collect();

    let start_batch = Instant::now();
    let (epoch_batch, best_acc_batch) = model_batch.train_with_batches(
        &train_inputs,
        &train_targets,
        &test_inputs,
        &test_targets,
        30,
        8, // batch_size
        0.01,
        5,
    );
    let time_batch = start_batch.elapsed();

    let (final_test_loss_batch, final_test_acc_batch) =
        model_batch.evaluate(&test_inputs_vec2, &test_targets);

    println!("\næ‰¹å¤„ç†è®­ç»ƒç»“æœ:");
    println!("  è®­ç»ƒæ—¶é—´: {:.2}s", time_batch.as_secs_f32());
    println!("  æœ€ä½³ epoch: {}", epoch_batch);
    println!("  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {:.2}%", best_acc_batch * 100.0);
    println!("  æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_batch * 100.0);

    // ============ å¯¹æ¯”åˆ†æ ============
    println!("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   æ€§èƒ½å¯¹æ¯”                                   â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    println!("è®­ç»ƒé€Ÿåº¦:");
    let speedup = time_single.as_secs_f32() / time_batch.as_secs_f32();
    println!("  å•æ ·æœ¬: {:.2}s", time_single.as_secs_f32());
    println!("  æ‰¹å¤„ç†: {:.2}s", time_batch.as_secs_f32());
    println!("  åŠ é€Ÿæ¯”: {:.2}x\n", speedup);

    println!("æ¨¡å‹æ€§èƒ½:");
    println!("  å•æ ·æœ¬æµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_single * 100.0);
    println!("  æ‰¹å¤„ç†æµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_batch * 100.0);

    let acc_diff = (final_test_acc_batch - final_test_acc_single) * 100.0;
    if acc_diff > 0.0 {
        println!("  æå‡: +{:.2}%\n", acc_diff);
    } else if acc_diff < 0.0 {
        println!("  ä¸‹é™: {:.2}%\n", acc_diff);
    } else {
        println!("  æŒå¹³\n");
    }

    // æ¨ç†ç¤ºä¾‹
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("æ¨ç†ç¤ºä¾‹ï¼ˆæ‰¹å¤„ç†æ¨¡å‹ï¼‰:");

    let test_sentences = vec![
        "this movie is great and wonderful",
        "this movie is terrible and boring",
        "I love this film it is amazing",
        "I hate this film it is awful",
    ];

    model_batch.set_training(false);

    for sentence in test_sentences {
        let tokens = dataset.vocab.encode(sentence, max_seq_len);
        let input_batch = Array2::from_shape_vec((1, tokens.len()), tokens).unwrap();

        let logits = model_batch.forward(&input_batch);
        let probs = logits.softmax(1);
        let prob_slice = probs.row(0);

        let pred_class = prob_slice
            .iter()
            .enumerate()
            .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
            .map(|(i, _)| i)
            .unwrap();

        let sentiment = if pred_class == 1 { "ç§¯æ" } else { "æ¶ˆæ" };
        let confidence = prob_slice[pred_class];

        println!("  æ–‡æœ¬: \"{}\"", sentence);
        println!("  é¢„æµ‹: {} (ç½®ä¿¡åº¦: {:.2}%)\n", sentiment, confidence * 100.0);
    }

    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   å®éªŒå®Œæˆï¼                                 â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}
