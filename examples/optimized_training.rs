//! ä¼˜åŒ–è®­ç»ƒç¤ºä¾‹
//!
//! å±•ç¤ºå­¦ä¹ ç‡è°ƒåº¦å’Œå…¶ä»–ä¼˜åŒ–æŠ€æœ¯çš„æ•ˆæœ

use mini_transformer::{
    TrainableTransformer, TextClassificationDataset,
    lr_scheduler::{StepLR, ConstantLR, LRScheduler},
    TensorExt,
};
use ndarray::Array2;
use std::time::Instant;

fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   è®­ç»ƒä¼˜åŒ–å¯¹æ¯”                               â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // åˆ›å»ºæ•°æ®é›†
    println!("ğŸ“Š åŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®é›†...");
    let dataset = mini_transformer::create_sentiment_dataset();

    println!("  è®­ç»ƒæ ·æœ¬: {}", dataset.train_len());
    println!("  æµ‹è¯•æ ·æœ¬: {}\n", dataset.test_len());

    // å‡†å¤‡æ•°æ®
    let max_seq_len = 10;
    let (train_inputs, train_targets) = dataset.encode_train(max_seq_len);
    let (test_inputs, test_targets) = dataset.encode_test(max_seq_len);

    // ============ å®éªŒ 1: å›ºå®šå­¦ä¹ ç‡ ============
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("å®éªŒ 1: å›ºå®šå­¦ä¹ ç‡ (0.01)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    let mut model_constant = TrainableTransformer::new(
        dataset.vocab.vocab_size(),
        128,
        4,
        2,
        256,
        max_seq_len,
        dataset.n_classes,
    );

    let constant_scheduler = ConstantLR::new(0.01);
    let start_constant = Instant::now();
    let (epoch_constant, best_acc_constant) = model_constant.train_with_scheduler(
        &train_inputs,
        &train_targets,
        &test_inputs,
        &test_targets,
        30,
        8,
        0.01,
        5,
        &constant_scheduler,
    );
    let time_constant = start_constant.elapsed();

    let test_inputs_vec1: Vec<Vec<usize>> = test_inputs
        .rows()
        .into_iter()
        .map(|row| row.to_vec())
        .collect();

    let (final_test_loss_constant, final_test_acc_constant) =
        model_constant.evaluate(&test_inputs_vec1, &test_targets);

    println!("\nå›ºå®šå­¦ä¹ ç‡ç»“æœ:");
    println!("  è®­ç»ƒæ—¶é—´: {:.2}s", time_constant.as_secs_f32());
    println!("  æœ€ä½³ epoch: {}", epoch_constant);
    println!("  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {:.2}%", best_acc_constant * 100.0);
    println!("  æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_constant * 100.0);

    // ============ å®éªŒ 2: æ­¥è¿›è¡°å‡ ============
    println!("\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("å®éªŒ 2: æ­¥è¿›è¡°å‡ (æ¯ 10 epoch è¡°å‡ 0.5)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    let mut model_step = TrainableTransformer::new(
        dataset.vocab.vocab_size(),
        128,
        4,
        2,
        256,
        max_seq_len,
        dataset.n_classes,
    );

    let step_scheduler = StepLR::new(0.01, 10, 0.5);
    let start_step = Instant::now();
    let (epoch_step, best_acc_step) = model_step.train_with_scheduler(
        &train_inputs,
        &train_targets,
        &test_inputs,
        &test_targets,
        30,
        8,
        0.01,
        5,
        &step_scheduler,
    );
    let time_step = start_step.elapsed();

    let test_inputs_vec2: Vec<Vec<usize>> = test_inputs
        .rows()
        .into_iter()
        .map(|row| row.to_vec())
        .collect();

    let (final_test_loss_step, final_test_acc_step) =
        model_step.evaluate(&test_inputs_vec2, &test_targets);

    println!("\næ­¥è¿›è¡°å‡ç»“æœ:");
    println!("  è®­ç»ƒæ—¶é—´: {:.2}s", time_step.as_secs_f32());
    println!("  æœ€ä½³ epoch: {}", epoch_step);
    println!("  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {:.2}%", best_acc_step * 100.0);
    println!("  æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_step * 100.0);

    // ============ å¯¹æ¯”åˆ†æ ============
    println!("\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   æ€§èƒ½å¯¹æ¯”                                   â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    println!("è®­ç»ƒæ—¶é—´:");
    println!("  å›ºå®šå­¦ä¹ ç‡: {:.2}s", time_constant.as_secs_f32());
    println!("  æ­¥è¿›è¡°å‡:   {:.2}s", time_step.as_secs_f32());

    let time_diff = if time_constant > time_step {
        (time_constant - time_step).as_secs_f32()
    } else {
        -(time_step - time_constant).as_secs_f32()
    };

    if time_diff > 0.0 {
        println!("  æ­¥è¿›è¡°å‡å¿« {:.2}s\n", time_diff);
    } else if time_diff < 0.0 {
        println!("  æ­¥è¿›è¡°å‡æ…¢ {:.2}s\n", -time_diff);
    } else {
        println!("  æ—¶é—´ç›¸åŒ\n");
    }

    println!("æ¨¡å‹æ€§èƒ½:");
    println!("  å›ºå®šå­¦ä¹ ç‡æµ‹è¯•å‡†ç¡®ç‡: {:.2}%", final_test_acc_constant * 100.0);
    println!("  æ­¥è¿›è¡°å‡æµ‹è¯•å‡†ç¡®ç‡:   {:.2}%", final_test_acc_step * 100.0);

    let acc_diff = (final_test_acc_step - final_test_acc_constant) * 100.0;
    if acc_diff > 0.0 {
        println!("  æå‡: +{:.2}%\n", acc_diff);
    } else if acc_diff < 0.0 {
        println!("  ä¸‹é™: {:.2}%\n", acc_diff);
    } else {
        println!("  æŒå¹³\n");
    }

    // å­¦ä¹ ç‡å˜åŒ–ç¤ºä¾‹
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("å­¦ä¹ ç‡å˜åŒ–ç¤ºä¾‹:");
    println!("Epoch | å›ºå®šå­¦ä¹ ç‡ | æ­¥è¿›è¡°å‡");
    println!("------|-----------|----------");
    for epoch in 0..30 {
        let const_lr = constant_scheduler.get_lr(epoch);
        let step_lr = step_scheduler.get_lr(epoch);
        if epoch % 5 == 0 || epoch < 5 {
            println!("{:5} | {:.6} | {:.6}", epoch + 1, const_lr, step_lr);
        }
    }

    // æ¨ç†ç¤ºä¾‹
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("æ¨ç†ç¤ºä¾‹ï¼ˆæ­¥è¿›è¡°å‡æ¨¡å‹ï¼‰:");

    let test_sentences = vec![
        "this movie is great",
        "this movie is terrible",
        "I love this film",
        "I hate this film",
    ];

    model_step.set_training(false);

    for sentence in test_sentences {
        let tokens = dataset.vocab.encode(sentence, max_seq_len);
        let input_batch = Array2::from_shape_vec((1, tokens.len()), tokens).unwrap();

        let logits = model_step.forward(&input_batch);
        let probs = logits.softmax(1);
        let prob_slice = probs.row(0);

        let pred_class = prob_slice
            .iter()
            .enumerate()
            .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
            .map(|(i, _)| i)
            .unwrap();

        let sentiment = if pred_class == 1 { "ç§¯æ" } else { "æ¶ˆæ" };
        let confidence = prob_slice[pred_class];

        println!("  æ–‡æœ¬: \"{}\"", sentence);
        println!("  é¢„æµ‹: {} (ç½®ä¿¡åº¦: {:.2}%)\n", sentiment, confidence * 100.0);
    }

    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘   å®éªŒå®Œæˆï¼                                 â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}
